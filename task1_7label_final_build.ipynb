{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # second gpu\n",
    "\n",
    "#### Task 2\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from matplotlib.ticker import MultipleLocator, AutoMinorLocator\n",
    "from scipy import interpolate\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import normaltest\n",
    "from scipy.stats import anderson\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def TMSD(traj, t_lags):\n",
    "    ttt = np.zeros_like(t_lags, dtype= float)\n",
    "    for idx, t in enumerate(t_lags): \n",
    "        for p in range(len(traj)-t):\n",
    "            ttt[idx] += (traj[p]-traj[p+t])**2            \n",
    "        ttt[idx] /= len(traj)-t    \n",
    "    return ttt\n",
    "\n",
    "def aging(traj, twind):\n",
    "    age = np.zeros(len(twind))\n",
    "    for i, it in enumerate(twind):\n",
    "        traj_seg = traj[0:it]\n",
    "        age[i] = TMSD(traj_seg,[1])[0]\n",
    "    return age\n",
    "\n",
    "def bound(val):\n",
    "    if val >= 100:\n",
    "        val = 100\n",
    "    elif val <= -100:\n",
    "        val = -100\n",
    "    else:\n",
    "        val = val\n",
    "    return val\n",
    "\n",
    "def trajec_feature(traces):\n",
    "    ## scaling factor\n",
    "    if np.mean(np.abs(np.diff(traces))) != 0:\n",
    "        sfac = (np.max(traces)-np.min(traces))/np.mean(np.abs(np.diff(traces)))\n",
    "    else:\n",
    "        sfac = 0\n",
    "    \n",
    "    mean = bound( np.mean(traces) )\n",
    "    ms = bound( np.std(traces) )\n",
    "    m3 = 0 ; m4 = 0\n",
    "    if ms != 0:\n",
    "        m3 = bound( np.mean(np.power(traces-mean,3))/(ms**3) )\n",
    "        m4 = bound( np.mean(np.power(traces-mean,4))/(ms**4) )\n",
    "\n",
    "\n",
    "\n",
    "    vtraces = np.diff(traces)\n",
    "    vmean = bound( np.mean(vtraces) )\n",
    "    vms = bound( np.std(vtraces) )\n",
    "    vm3 = 0 ; vm4 = 0\n",
    "    if vms != 0:\n",
    "        vm3 = bound( np.mean(np.power(vtraces-vmean,3))/(vms**3) )\n",
    "        vm4 = bound( np.mean(np.power(vtraces-vmean,4))/(vms**4) )\n",
    "\n",
    "    atraces = np.diff(vtraces)\n",
    "    amean = bound( np.mean(atraces) )\n",
    "    ams = bound( np.std(atraces) )\n",
    "    am3 = 0 ; am4 = 0\n",
    "    if ams != 0:\n",
    "        am3 = bound( np.mean(np.power(atraces-amean,3))/(ams**3) )\n",
    "        am4 = bound( np.mean(np.power(atraces-amean,4))/(ams**4) )\n",
    "\n",
    "\n",
    "    f2 = bound( np.max(vtraces) - np.min(vtraces) )\n",
    "    f3 = bound( np.max(atraces) - np.min(atraces) )\n",
    "    \n",
    "       \n",
    "    tlag = np.linspace(1, len(traces)-1, 10, dtype = 'int')\n",
    "    \n",
    "    msd = TMSD(traces, tlag)\n",
    "    A = np.vstack([np.log(tlag), np.ones(len(np.log(tlag)))]).T\n",
    "    nw1, nw0 = np.linalg.lstsq(A, np.log(msd), rcond=None)[0]\n",
    "\n",
    "    nw1 = bound(nw1)\n",
    "    nw0 = bound(nw0)\n",
    "    \n",
    "    tlag = np.linspace(10, len(traces)-1, 10, dtype = 'int')\n",
    "    age = aging(traces, tlag)\n",
    "    A = np.vstack([np.log(tlag), np.ones(len(np.log(tlag)))]).T\n",
    "    age_nw1, age_nw0 = np.linalg.lstsq(A, np.log(age), rcond=None)[0]\n",
    "    \n",
    "    age_nw1 = bound(age_nw1)\n",
    "\n",
    "    sh_stat, sh_p = shapiro(vtraces)\n",
    "    \n",
    "    if sh_p >= 0.1:\n",
    "        sh_stat = -1      \n",
    "    sh_stat = bound(sh_stat)\n",
    "    \n",
    "    if len(vtraces) > 20 :\n",
    "        nom_stat, nom_p = normaltest(vtraces)\n",
    "        if nom_p >= 0.1:\n",
    "            nom_stat = -1\n",
    "        and_result = anderson(vtraces).statistic\n",
    "    \n",
    "    else:\n",
    "        nom_stat = -0.5\n",
    "        and_result = -0.5\n",
    "       \n",
    "    nom_stat = bound(nom_stat)\n",
    "    and_result = bound(and_result)\n",
    "\n",
    "    \n",
    "    feature = np.asarray([mean, ms, m3, m4, vmean, vms, vm3, vm4, \\\n",
    "                        amean, ams, am3, nw1, nw0, age_nw1, \\\n",
    "                        sfac, am4, f2, f3, sh_stat, and_result])\n",
    "    \n",
    "    \n",
    "\n",
    "    feature = np.append(feature,msd)\n",
    "    feature = np.append(feature,age)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    return feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data ready\n",
      "elapsed time: 0 min 8 sec\n"
     ]
    }
   ],
   "source": [
    "file = '../USED_DATA/task_sim_1d_0_nmax5000.pkl'\n",
    "nmax = 5000\n",
    "\n",
    "f = open(file, 'rb')\n",
    "my_list = pickle.load(f)\n",
    "\n",
    "trajecs = my_list['trajec']\n",
    "model_id = my_list['label_id']\n",
    "labels = my_list['label']\n",
    "elabels = my_list['elabel']\n",
    "\n",
    "f.flush()\n",
    "f.close()\n",
    "\n",
    "\n",
    "ncase = int(len(trajecs)/nmax)\n",
    "\n",
    "\n",
    "tstart = time.time()\n",
    "\n",
    "\n",
    "ndiv = 100\n",
    "namp = 0.01\n",
    "\n",
    "data_set = np.zeros((len(trajecs),ndiv))\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "for i in range(len(trajecs)):\n",
    "    trajec = trajecs[i]\n",
    "    ret = len(trajecs[i])\n",
    "    convt = ndiv/ret\n",
    "    \n",
    "    ti_new = np.linspace(0, len(trajec), ndiv)\n",
    "    postck = interpolate.splrep(np.arange(0, len(trajec), 1), trajec)\n",
    "    trajec = interpolate.splev(ti_new, postck) \n",
    "\n",
    "    strajec = scaler.fit_transform(np.reshape(trajec,(-1,1))).T[0]       \n",
    "    data_set[i] = strajec + namp * convt * np.random.normal(0,1,size=100)\n",
    "\n",
    "    \n",
    "tend = time.time()\n",
    "\n",
    "print('data ready')\n",
    "print('elapsed time: {0:.0f} min {1:.0f} sec'.format((tend-tstart)//60, (tend-tstart)%60))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 1 min 14 sec\n"
     ]
    }
   ],
   "source": [
    "train_size = 4000\n",
    "test_size = 1000\n",
    "f_dim = 40\n",
    "\n",
    "idxs = np.arange(0, nmax, dtype='int')\n",
    "np.random.shuffle(idxs)\n",
    "\n",
    "idx = idxs[:train_size]\n",
    "idx_test = idxs[train_size:train_size+test_size]\n",
    "\n",
    "train_data = np.zeros((ncase*train_size,ndiv,1))\n",
    "train_info = np.zeros((ncase*train_size,f_dim))\n",
    "train_label = np.zeros((ncase*train_size))\n",
    "\n",
    "test_data = np.zeros((ncase*test_size,ndiv,1))\n",
    "test_info = np.zeros((ncase*test_size,f_dim))\n",
    "test_label = np.zeros((ncase*test_size))\n",
    "\n",
    "\n",
    "\n",
    "tstart = time.time()\n",
    "\n",
    "icount = 0\n",
    "for ic in range(ncase):\n",
    "    for j, iid in enumerate(idx):\n",
    "        train_data[icount,:,0] = data_set[ic*nmax+iid]\n",
    "        train_info[icount] = trajec_feature(data_set[ic*nmax+iid]) \n",
    "        train_label[icount] = elabels[ic*nmax + iid]\n",
    "        icount = icount + 1\n",
    "\n",
    "icount = 0\n",
    "for ic in range(ncase):\n",
    "    for j, iid in enumerate(idx_test):\n",
    "        test_data[icount,:,0] = data_set[ic*nmax+iid]\n",
    "        test_info[icount] = trajec_feature(data_set[ic*nmax+iid]) \n",
    "        test_label[icount] = elabels[ic*nmax + iid]\n",
    "        icount = icount + 1\n",
    "\n",
    "tend = time.time()\n",
    "\n",
    "print('elapsed time: {0:.0f} min {1:.0f} sec'.format((tend-tstart)//60, (tend-tstart)%60))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "machine_id = 0\n",
    "estop_pat = 50\n",
    "rlr_pat = 30\n",
    "\n",
    "epnum = 1000\n",
    "bsize = 128\n",
    "\n",
    "l_dim = f_dim\n",
    "\n",
    "MODEL_SAVE_FOLDER_PATH = './test_build/'\n",
    "if not os.path.exists(MODEL_SAVE_FOLDER_PATH):\n",
    "    os.mkdir(MODEL_SAVE_FOLDER_PATH)\n",
    "    \n",
    "model_path = MODEL_SAVE_FOLDER_PATH + 'task1_{0:}.hdf5'.format(machine_id)\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath=model_path, monitor='val_loss', mode = 'min',\\\n",
    "                                verbose=1, save_best_only=True)\n",
    "\n",
    "stopping = keras.callbacks.EarlyStopping(monitor='val_loss', mode = 'min', patience=estop_pat)\n",
    "      \n",
    "rlr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=rlr_pat, min_lr=0.000001, \\\n",
    "                        verbose=1, min_delta=1e-5)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 100, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 100, 128)     1408        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 100, 128)     512         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 100, 128)     0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 100, 128)     114816      activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 100, 128)     512         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 100, 256)     2816        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 100, 128)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 100, 256)     1024        conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 100, 128)     256         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 100, 128)     82048       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 100, 256)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 100, 128)     512         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 100, 128)     512         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 100, 256)     459008      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 100, 128)     0           batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 100, 256)     1024        conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 100, 128)     0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 100, 256)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 100, 256)     33024       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 100, 256)     327936      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 100, 256)     1024        conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 100, 256)     1024        conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 100, 256)     0           batch_normalization_7[0][0]      \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 100, 256)     0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 100, 256)     655616      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 100, 256)     1024        conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 100, 256)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 100, 256)     459008      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 100, 256)     1024        conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 100, 256)     0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 100, 256)     327936      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 100, 256)     1024        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 100, 256)     1024        conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 100, 256)     0           batch_normalization_11[0][0]     \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 100, 256)     0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 256)          0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 40)           10280       global_average_pooling1d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 2,484,392\n",
      "Trainable params: 2,479,272\n",
      "Non-trainable params: 5,120\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 80)           0           input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 1)            41111       concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 41,111\n",
      "Trainable params: 40,151\n",
      "Non-trainable params: 960\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 100, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "functional_1 (Functional)       (None, 40)           2484392     input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "functional_3 (Functional)       (None, 1)            41111       functional_1[0][0]               \n",
      "                                                                 input_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,525,503\n",
      "Trainable params: 2,519,423\n",
      "Non-trainable params: 6,080\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/1000\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.5331\n",
      "Epoch 00001: val_loss improved from inf to 0.40627, saving model to ./test_build/task1_0.hdf5\n",
      "219/219 [==============================] - 132s 604ms/step - loss: 0.5331 - val_loss: 0.4063\n",
      "Epoch 2/1000\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.4078\n",
      "Epoch 00002: val_loss improved from 0.40627 to 0.31713, saving model to ./test_build/task1_0.hdf5\n",
      "219/219 [==============================] - 131s 600ms/step - loss: 0.4078 - val_loss: 0.3171\n",
      "Epoch 3/1000\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.3460\n",
      "Epoch 00003: val_loss improved from 0.31713 to 0.26173, saving model to ./test_build/task1_0.hdf5\n",
      "219/219 [==============================] - 132s 603ms/step - loss: 0.3460 - val_loss: 0.2617\n",
      "Epoch 4/1000\n",
      "  4/219 [..............................] - ETA: 1:37 - loss: 0.3327"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-6b70a22e89ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0mresnet_mlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mae'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m hist = resnet_mlp.fit([train_data, train_info], train_label, batch_size=bsize, epochs=epnum,\n\u001b[0m\u001b[1;32m    191\u001b[0m                  \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_info\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                  callbacks=[rlr, stopping, checkpoint])     \n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# act = 'selu'\n",
    "# initializer = tf.keras.initializers.LecunNormal()\n",
    "act = 'relu'\n",
    "initializer = tf.keras.initializers.HeUniform()\n",
    "\n",
    "def build_model_resnet(input_shape, l_dim):\n",
    "\n",
    "    n_feature_maps = 128\n",
    "#     n_feature_maps = 64\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "    # BLOCK 1\n",
    "\n",
    "    conv_x = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=10, strides=1,  \\\n",
    "                                 padding='same', kernel_initializer=initializer)(input_layer)\n",
    "    conv_x = keras.layers.BatchNormalization()(conv_x)\n",
    "    conv_x = keras.layers.Activation(act)(conv_x)\n",
    "\n",
    "    conv_y = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=7, strides=1,  \\\n",
    "                                 padding='same', kernel_initializer=initializer)(conv_x)\n",
    "    conv_y = keras.layers.BatchNormalization()(conv_y)\n",
    "    conv_y = keras.layers.Activation(act)(conv_y)\n",
    "\n",
    "    conv_z = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=5, strides=1,  \\\n",
    "                                 padding='same', kernel_initializer=initializer)(conv_y)\n",
    "    conv_z = keras.layers.BatchNormalization()(conv_z)\n",
    "\n",
    "    shortcut_y = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=1, strides=1,  \\\n",
    "                                 padding='same', kernel_initializer=initializer)(input_layer)\n",
    "    shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
    "\n",
    "    output_block_1 = keras.layers.add([shortcut_y, conv_z])\n",
    "    output_block_1 = keras.layers.Activation(act)(output_block_1)\n",
    "\n",
    "    # BLOCK 2\n",
    "\n",
    "    conv_x = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=10, strides=1,  \\\n",
    "                                 padding='same', kernel_initializer=initializer)(input_layer)\n",
    "    conv_x = keras.layers.BatchNormalization()(conv_x)\n",
    "    conv_x = keras.layers.Activation(act)(conv_x)\n",
    "\n",
    "    conv_y = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=7, strides=1,  \\\n",
    "                                 padding='same', kernel_initializer=initializer)(conv_x)\n",
    "    conv_y = keras.layers.BatchNormalization()(conv_y)\n",
    "    conv_y = keras.layers.Activation(act)(conv_y)\n",
    "\n",
    "    conv_z = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=5, strides=1,  \\\n",
    "                                 padding='same', kernel_initializer=initializer)(conv_y)\n",
    "    conv_z = keras.layers.BatchNormalization()(conv_z)\n",
    "\n",
    "    shortcut_y = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=1, strides=1,  \\\n",
    "                                 padding='same', kernel_initializer=initializer)(output_block_1)\n",
    "    shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
    "\n",
    "    output_block_2 = keras.layers.add([shortcut_y, conv_z])\n",
    "    output_block_2 = keras.layers.Activation(act)(output_block_2)\n",
    "\n",
    "    # BLOCK 3\n",
    "\n",
    "    conv_x = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=10, strides=1,  \\\n",
    "                                 padding='same', kernel_initializer=initializer)(output_block_2)\n",
    "    conv_x = keras.layers.BatchNormalization()(conv_x)\n",
    "    conv_x = keras.layers.Activation(act)(conv_x)\n",
    "\n",
    "    conv_y = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=7, strides=1,  \\\n",
    "                                 padding='same', kernel_initializer=initializer)(conv_x)\n",
    "    conv_y = keras.layers.BatchNormalization()(conv_y)\n",
    "    conv_y = keras.layers.Activation(act)(conv_y)\n",
    "\n",
    "    conv_z = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=5, strides=1,  \\\n",
    "                                 padding='same', kernel_initializer=initializer)(conv_y)\n",
    "    conv_z = keras.layers.BatchNormalization()(conv_z)\n",
    "\n",
    "    shortcut_y = keras.layers.BatchNormalization()(output_block_2)\n",
    "\n",
    "    output_block_3 = keras.layers.add([shortcut_y, conv_z])\n",
    "    output_block_3 = keras.layers.Activation(act)(output_block_3)\n",
    "\n",
    "    # FINAL\n",
    "\n",
    "    gap_layer = keras.layers.GlobalAveragePooling1D()(output_block_3)\n",
    "\n",
    "    output_layer = keras.layers.Dense(l_dim, activation=act)(gap_layer)\n",
    "\n",
    "    model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def MLP_read(l_dim, f_dim):\n",
    "\n",
    "    l_input = keras.layers.Input(shape=(l_dim,))\n",
    "    f_input = keras.layers.Input(shape=(f_dim,))\n",
    "    concated = keras.layers.concatenate([l_input, f_input])\n",
    "\n",
    "    mlp_clf = keras.models.Sequential()\n",
    "    \n",
    "    mlp_clf.add(keras.layers.Dense(100, activation='linear', input_dim=l_dim + f_dim, \\\n",
    "                                  kernel_initializer=initializer))\n",
    "    mlp_clf.add(keras.layers.BatchNormalization())\n",
    "    mlp_clf.add(keras.layers.Activation(act))\n",
    "    mlp_clf.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "\n",
    "    mlp_clf.add(keras.layers.Dense(100, activation='linear', kernel_initializer=initializer))\n",
    "    mlp_clf.add(keras.layers.BatchNormalization())\n",
    "    mlp_clf.add(keras.layers.Activation(act))\n",
    "    mlp_clf.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "\n",
    "    mlp_clf.add(keras.layers.Dense(100, activation='linear', kernel_initializer=initializer))\n",
    "    mlp_clf.add(keras.layers.BatchNormalization())\n",
    "    mlp_clf.add(keras.layers.Activation(act))\n",
    "    mlp_clf.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "\n",
    "    mlp_clf.add(keras.layers.Dense(50, activation='linear', kernel_initializer=initializer))\n",
    "    mlp_clf.add(keras.layers.BatchNormalization())\n",
    "    mlp_clf.add(keras.layers.Activation(act))\n",
    "    mlp_clf.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "\n",
    "    mlp_clf.add(keras.layers.Dense(50, activation='linear', kernel_initializer=initializer))\n",
    "    mlp_clf.add(keras.layers.BatchNormalization())\n",
    "    mlp_clf.add(keras.layers.Activation(act))\n",
    "    mlp_clf.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "    mlp_clf.add(keras.layers.Dense(50, activation='linear', kernel_initializer=initializer))\n",
    "    mlp_clf.add(keras.layers.BatchNormalization())\n",
    "    mlp_clf.add(keras.layers.Activation(act))\n",
    "    mlp_clf.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "    mlp_clf.add(keras.layers.Dense(10, activation='linear', kernel_initializer=initializer))\n",
    "    mlp_clf.add(keras.layers.BatchNormalization())\n",
    "    mlp_clf.add(keras.layers.Activation(act))\n",
    "    mlp_clf.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "    mlp_clf.add(keras.layers.Dense(10, activation='linear', kernel_initializer=initializer))\n",
    "    mlp_clf.add(keras.layers.BatchNormalization())\n",
    "    mlp_clf.add(keras.layers.Activation(act))\n",
    "    mlp_clf.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "    mlp_clf.add(keras.layers.Dense(10, activation='linear', kernel_initializer=initializer))\n",
    "    mlp_clf.add(keras.layers.BatchNormalization())\n",
    "    mlp_clf.add(keras.layers.Activation(act))\n",
    "    mlp_clf.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "    mlp_clf.add(keras.layers.Dense(1, activation=act))\n",
    "    \n",
    "    out = mlp_clf(concated)\n",
    "\n",
    "    mlp_model = keras.models.Model([l_input, f_input], out)\n",
    "\n",
    "    return mlp_model\n",
    "\n",
    "\n",
    "\n",
    "l_dim = f_dim\n",
    "\n",
    "input_shape = (ndiv,1,)\n",
    "res = build_model_resnet(input_shape, l_dim)\n",
    "res.summary()\n",
    "keras.utils.plot_model(res, to_file=MODEL_SAVE_FOLDER_PATH +'resnet_t1.png', \\\n",
    "                       show_shapes=True, show_layer_names=True)\n",
    "\n",
    "mlp_clf = MLP_read(l_dim, f_dim)\n",
    "mlp_clf.summary()\n",
    "keras.utils.plot_model(mlp_clf, to_file=MODEL_SAVE_FOLDER_PATH +'mlp_clf_t1.png', \\\n",
    "                       show_shapes=True, show_layer_names=True)\n",
    "\n",
    "indata = keras.layers.Input(shape=(ndiv,1,))\n",
    "f_info = keras.layers.Input(shape=(f_dim,))\n",
    "\n",
    "resnet_out = res(indata)\n",
    "output = mlp_clf([resnet_out, f_info])\n",
    "\n",
    "\n",
    "resnet_mlp = keras.models.Model([indata, f_info],output)\n",
    "resnet_mlp.summary()\n",
    "keras.utils.plot_model(resnet_mlp, to_file=MODEL_SAVE_FOLDER_PATH +'resnet_mlp_t1.png', \\\n",
    "                       show_shapes=True, show_layer_names=True)\n",
    "\n",
    "\n",
    "# from keras.utils import plot_model\n",
    "resnet_mlp.compile(loss='mae', optimizer=keras.optimizers.Adam(0.001))\n",
    "\n",
    "hist = resnet_mlp.fit([train_data, train_info], train_label, batch_size=bsize, epochs=epnum,\n",
    "                 verbose=1, validation_data=([test_data, test_info], test_label),\\\n",
    "                 callbacks=[rlr, stopping, checkpoint])     \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Learning Curves')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('ACC')\n",
    "plt.plot(hist.history['val_loss'], label='7label')\n",
    "plt.yscale('log')\n",
    "plt.savefig( MODEL_SAVE_FOLDER_PATH + 'learning_cur_task1.png')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-d0fafdad5c72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0micount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mic\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnmax\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0miid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mtest_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0micount\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrajec_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mic\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnmax\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0miid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mtest_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0micount\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mic\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnmax\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0miid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0micount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0micount\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-9068528d2146>\u001b[0m in \u001b[0;36mtrajec_feature\u001b[0;34m(traces)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mtlag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0mage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtlag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtlag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtlag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mage_nw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage_nw0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstsq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-9068528d2146>\u001b[0m in \u001b[0;36maging\u001b[0;34m(traj, twind)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtwind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtraj_seg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTMSD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraj_seg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-9068528d2146>\u001b[0m in \u001b[0;36mTMSD\u001b[0;34m(traj, t_lags)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_lags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mttt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtraj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtraj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mttt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mttt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loaded = keras.models.load_model(model_path)\n",
    "\n",
    "\n",
    "###############\n",
    "file = '../USED_DATA/task_sim_1d_0_nmax5000.pkl'\n",
    "machine_id = 1\n",
    "###############\n",
    "\n",
    "\n",
    "f = open(file, 'rb')\n",
    "my_list = pickle.load(f)\n",
    "trajecs = my_list['trajec']\n",
    "model_id = my_list['label_id']\n",
    "labels = my_list['label']\n",
    "elabels = my_list['elabel']\n",
    "f.flush()\n",
    "f.close()\n",
    "\n",
    "ndiv = 100\n",
    "namp = 0.001\n",
    "\n",
    "data_set = np.zeros((len(trajecs),ndiv))\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "for i in range(len(trajecs)):\n",
    "    trajec = trajecs[i]\n",
    "    ret = len(trajecs[i])\n",
    "    convt = ndiv/ret\n",
    "    \n",
    "    ti_new = np.linspace(0, len(trajec), ndiv)\n",
    "    postck = interpolate.splrep(np.arange(0, len(trajec), 1), trajec)\n",
    "    trajec = interpolate.splev(ti_new, postck) \n",
    "\n",
    "    strajec = scaler.fit_transform(np.reshape(trajec,(-1,1))).T[0]       \n",
    "    data_set[i] = strajec + namp * convt * np.random.normal(0,1,size=100)\n",
    "\n",
    "\n",
    "\n",
    "train_size = 3000\n",
    "test_size = 2000\n",
    "f_dim = 40\n",
    "\n",
    "idxs = np.arange(0, nmax, dtype='int')\n",
    "np.random.shuffle(idxs)\n",
    "idx = idxs[:train_size]\n",
    "idx_test = idxs[train_size:train_size+test_size]\n",
    "train_data = np.zeros((ncase*train_size,ndiv,1))\n",
    "train_info = np.zeros((ncase*train_size,f_dim))\n",
    "train_label = np.zeros((ncase*train_size))\n",
    "test_data = np.zeros((ncase*test_size,ndiv,1))\n",
    "test_info = np.zeros((ncase*test_size,f_dim))\n",
    "test_label = np.zeros((ncase*test_size))\n",
    "\n",
    "tstart = time.time()\n",
    "icount = 0\n",
    "for ic in range(ncase):\n",
    "    for j, iid in enumerate(idx):\n",
    "        train_data[icount,:,0] = data_set[ic*nmax+iid]\n",
    "        train_info[icount] = trajec_feature(data_set[ic*nmax+iid]) \n",
    "        train_label[icount] = elabels[ic*nmax + iid]\n",
    "        icount = icount + 1\n",
    "\n",
    "icount = 0\n",
    "for ic in range(ncase):\n",
    "    for j, iid in enumerate(idx_test):\n",
    "        test_data[icount,:,0] = data_set[ic*nmax+iid]\n",
    "        test_info[icount] = trajec_feature(data_set[ic*nmax+iid]) \n",
    "        test_label[icount] = elabels[ic*nmax + iid]\n",
    "        icount = icount + 1\n",
    "\n",
    "tend = time.time()\n",
    "\n",
    "print('elapsed time: {0:.0f} min {1:.0f} sec'.format((tend-tstart)//60, (tend-tstart)%60))\n",
    "\n",
    "estop_pat = 100\n",
    "rlr_pat = 30\n",
    "\n",
    "epnum = 1000\n",
    "bsize = 128\n",
    "\n",
    "l_dim = f_dim\n",
    "\n",
    "MODEL_SAVE_FOLDER_PATH = './Final_build/'\n",
    "if not os.path.exists(MODEL_SAVE_FOLDER_PATH):\n",
    "    os.mkdir(MODEL_SAVE_FOLDER_PATH)\n",
    "    \n",
    "model_path = MODEL_SAVE_FOLDER_PATH + 'task1_{0:}.hdf5'.format(machine_id)\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath=model_path, monitor='val_loss', mode = 'min',\\\n",
    "                                verbose=1, save_best_only=True)\n",
    "\n",
    "stopping = keras.callbacks.EarlyStopping(monitor='val_loss', mode = 'min', patience=estop_pat)\n",
    "      \n",
    "rlr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=rlr_pat, min_lr=0.000001, \\\n",
    "                        verbose=1, min_delta=1e-5)\n",
    "\n",
    "\n",
    "loaded.compile(loss='mae', optimizer=keras.optimizers.Adam())\n",
    "\n",
    "hist = loaded.fit([train_data, train_info], train_label, batch_size=bsize, epochs=epnum,\n",
    "                 verbose=1, validation_data=([test_data, test_info], test_label),\\\n",
    "                 callbacks=[rlr, stopping, checkpoint])     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Learning Curves')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('ACC')\n",
    "plt.plot(hist.history['val_loss'], label='7label')\n",
    "plt.yscale('log')\n",
    "plt.savefig( MODEL_SAVE_FOLDER_PATH + 'learning_cur_task1_1.png')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
